{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build 30 s dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Build up datasets of 30 sec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import os\n",
    "import computeDEL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "import scipy.io as spio\n",
    "import wrapFunctions #import wrap180, wrap360, wrapList\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "justOne = True #for debugging, try just one file?\n",
    "\n",
    "# Inputs\n",
    "dataRoot = 'Y:\\\\Wind\\\\Confidential\\\\Projects\\\\Cert\\\\D-Z\\\\Field Testing\\\\GE 1.5SLE\\\\Tests\\\\FY16\\\\NextEra Yaw Error Project\\\\Wind Vane Misalignment - SRDana\\\\Data\\\\FT_Formatted Fast Data'\n",
    "Fs = 50. #Hz\n",
    "fileLength = 600. #s\n",
    "\n",
    "# Outputs\n",
    "interval = 30 #s\n",
    "dataOut = 'data30_redo'\n",
    "\n",
    "# Limit range\n",
    "powLim = 50. #kW (making at least some power)\n",
    "yawLim = [225., 25.] #note this is an or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Long Version\n",
    "signalList = [\n",
    " 'OPC_In_RotorSpd',\n",
    " 'Air_Press_1',\n",
    " 'Mainshaft_Downwind_Bend_0',\n",
    " 'BL1_FlapMom',\n",
    " 'Azimuth',\n",
    " 'Blade_1_Edge',\n",
    " 'TowerBaseTorque',\n",
    " 'Yaw_Encoder',\n",
    " 'TB_ForeAft',\n",
    " 'WS1_90m',\n",
    " 'LSSDW_Mz',\n",
    " 'LSSDW_My',\n",
    " 'TTTq',\n",
    " 'TT_ForeAft',\n",
    " 'MainShaftBending_0',\n",
    " 'Temp1',\n",
    " 'WindSpeed_80m',\n",
    " 'LSSDW_M90',\n",
    " 'ScanErrors',\n",
    " 'MSExcelTimestamp',\n",
    " 'Pitch_Blade1',\n",
    " 'LSSDW_Tq',\n",
    " 'TT_SideSide',\n",
    " 'ApparentPower',\n",
    " 'apparantVane',\n",
    " 'MainShaftTorque',\n",
    " 'WD_Nacelle',\n",
    " 'LateScans',\n",
    " 'BL1_EdgeMom',\n",
    " 'Mainshaft_Downwind_Torque',\n",
    " 'LidarOffset',\n",
    " 'LabVIEWTimestamp',\n",
    " 'Blade_1_Flap',\n",
    " 'Mainshaft_Downwind_Bend_90',\n",
    " 'TowerTopTorque',\n",
    " 'WD1_87m',\n",
    " 'MainShaftTorqueNew',\n",
    " 'TBTq',\n",
    " 'TB_SideSide']\n",
    "\n",
    "angularSignalList = ['Azimuth','Yaw_Encoder','Pitch_Blade1','WD_Nacelle','apparantVane','WD1_87m']\n",
    "\n",
    "m10list = ['BL1_FlapMom','BL1_EdgeMom'] # list of loads which use an m-value of 10, the rest are 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Condensed Version\n",
    "signalList = [\n",
    " 'OPC_In_RotorSpd',\n",
    " 'BL1_FlapMom',\n",
    " 'Azimuth',\n",
    " 'TowerBaseTorque',\n",
    " 'Yaw_Encoder',\n",
    " 'TB_ForeAft',\n",
    " 'WS1_90m',\n",
    " 'LSSDW_Mz',\n",
    " 'LSSDW_My',\n",
    " 'WindSpeed_80m',\n",
    " 'TTTq',\n",
    " 'TT_ForeAft',\n",
    " 'Pitch_Blade1',\n",
    " 'LSSDW_Tq',\n",
    " 'TT_SideSide',\n",
    " 'ApparentPower',\n",
    " 'apparantVane',\n",
    " 'WD_Nacelle',\n",
    " 'BL1_EdgeMom',\n",
    " 'Mainshaft_Downwind_Torque',\n",
    " 'LidarOffset',\n",
    " 'LabVIEWTimestamp',\n",
    " 'Mainshaft_Downwind_Bend_90',\n",
    " 'TowerTopTorque',\n",
    " 'WD1_87m',\n",
    " 'TBTq',\n",
    " 'TB_SideSide']\n",
    "\n",
    "angularSignalList = ['Azimuth','Yaw_Encoder','Pitch_Blade1','WD_Nacelle','apparantVane','WD1_87m']\n",
    "\n",
    "m10list = ['BL1_FlapMom','BL1_EdgeMom'] # list of loads which use an m-value of 10, the rest are 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculated parameters\n",
    "numBins = int(fileLength/interval)\n",
    "binEdge = range(0,int(fileLength*Fs) +int(interval * Fs) ,int(interval * Fs))\n",
    "binEdge[0] = -1\n",
    "#binEdge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get list of folders to process\n",
    "dateFolders = os.listdir(dataRoot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up output files\n",
    "outputFile = os.path.join(dataOut,'dataFile.csv')\n",
    "filenameFile = os.path.join(dataOut,'filenames.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up a load file functions\n",
    "\n",
    "# From http://stackoverflow.com/questions/7008608/scipy-io-loadmat-nested-structures-i-e-dictionaries\n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    '''\n",
    "    try:\n",
    "        data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    except:\n",
    "        print 'some issue loading'\n",
    "        return False\n",
    "    return _check_keys(data)\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    checks if entries in dictionary are mat-objects. If yes\n",
    "    todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], spio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict        \n",
    "\n",
    "def _todict(matobj):\n",
    "    '''\n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "# Finally the load file function\n",
    "\n",
    "def loadGEfile(filename):\n",
    "\n",
    "    data = loadmat(filename)\n",
    "    if data:\n",
    "        data = data['data_out']\n",
    "\n",
    "        # Add the apparant vane signal\n",
    "        data['apparantVane'] = dict()\n",
    "        data['apparantVane']['processed'] =  np.array(wrapFunctions.wrapList(data['WD1_87m']['processed'] - data['Yaw_Encoder']['processed'] ))\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Angular mean and standard deviation helper and del helper function\n",
    "\n",
    "import math\n",
    "\n",
    "def mixedMean(ser):\n",
    "    \n",
    "    #print ser.name\n",
    "    \n",
    "    #agg = pd.DataFrame()\n",
    "    #for col in df.columns:\n",
    "    if ser.name in angularSignalList:\n",
    "        #print  ser.name + ' is angular'\n",
    "        xAng += np.cos(ser*(np.pi/180.))\n",
    "        yAng += np.sin(ser*(np.pi/180.))\n",
    "\n",
    "        sMean = math.atan2(yAng,xAng)*(180./np.pi)\n",
    "        \n",
    "    else:\n",
    "        sMean = np.mean(ser)\n",
    "    return sMean\n",
    "\n",
    "def mixedDEL(ser):\n",
    "    \n",
    "    if ser.name in m10list:\n",
    "        return computeDEL.computeDEL(ser,1./Fs,10.)\n",
    "    else:\n",
    "        return computeDEL.computeDEL(ser,1./Fs,4.)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a list of already processed files\n",
    "processedFiles = []\n",
    "with open(filenameFile) as f:\n",
    "    contents = f.readlines()\n",
    "for i in contents:\n",
    "    processedFiles.append(i.rstrip('\\n'))\n",
    "#print processedFiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2016-08-03\n",
      "File DOE15_FastData_2016_08_03_10_56_07_50Hz_Formatted_Data.mat is already processed\n",
      "... file DOE15_FastData_2016_08_03_11_06_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_11_16_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_11_26_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_11_36_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_11_46_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_11_56_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_12_06_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_12_16_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_12_26_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_12_36_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_12_46_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_12_56_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_13_06_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_13_16_07_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_13_26_06_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_13_36_06_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_13_46_06_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_13_56_06_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_14_06_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_14_16_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_14_26_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_14_36_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_14_46_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_14_56_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_15_06_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_15_16_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_15_26_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_15_36_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_15_46_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_15_56_08_50Hz_Formatted_Data.mat\n",
      "creating file\n",
      "... file DOE15_FastData_2016_08_03_16_06_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_16_16_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_16_26_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_16_36_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_16_46_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_16_56_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_17_06_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_17_16_08_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_17_26_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_17_36_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_17_46_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_17_56_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_18_06_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_18_16_09_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_18_26_09_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_18_36_09_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_18_46_09_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_18_56_09_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_19_06_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_19_16_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_19_26_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_19_36_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_19_46_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_19_56_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_20_06_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_20_16_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_20_26_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_20_36_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_20_46_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_20_56_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_21_06_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_21_16_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_21_26_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_21_36_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_21_46_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_21_56_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_22_06_09_50Hz_Formatted_Data.mat\n",
      "..... no rows meet criteria, skipping\n",
      "... file DOE15_FastData_2016_08_03_22_16_09_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_22_26_09_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_22_36_09_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_22_46_09_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_22_56_09_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_23_06_09_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_23_16_08_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_23_26_08_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_23_36_08_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_23_46_08_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_03_23_56_08_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "Processing 2016-08-04\n",
      "... file DOE15_FastData_2016_08_04_00_06_08_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_04_00_16_08_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_04_00_26_08_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_04_00_36_08_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_04_00_46_08_50Hz_Formatted_Data.mat\n",
      "some issue loading\n",
      "... file DOE15_FastData_2016_08_04_00_56_08_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_04_01_06_08_50Hz_Formatted_Data.mat\n",
      "creating file\n",
      "... file DOE15_FastData_2016_08_04_01_16_08_50Hz_Formatted_Data.mat\n",
      "...... WRITE TO FILE\n",
      "... file DOE15_FastData_2016_08_04_01_26_08_50Hz_Formatted_Data.mat"
     ]
    }
   ],
   "source": [
    "#os.remove(outputFile)\n",
    "\n",
    "\n",
    "\n",
    "for dateFolder in dateFolders:\n",
    "    print 'Processing ' + dateFolder\n",
    "    \n",
    "    folder = os.path.join(dataRoot,dateFolder)\n",
    "    \n",
    "    # Get a list of mat files\n",
    "    files = os.listdir(folder)\n",
    "    files = [f for f in files if '.mat' in f]\n",
    "    \n",
    "    for f in files:\n",
    "        \n",
    "        # Check if we've allready processed this one\n",
    "        if f in processedFiles:\n",
    "            print 'File ' + f + ' is already processed'\n",
    "            continue\n",
    "        \n",
    "        fullFile = os.path.join(folder,f)\n",
    "        print '... file ' + f\n",
    "        \n",
    "        # Load the file\n",
    "        data = loadGEfile(fullFile)\n",
    "        \n",
    "        if not data:\n",
    "            'skipping file due to badness'\n",
    "            continue\n",
    "        \n",
    "        #Simplify into a dataframe\n",
    "        dataCon = pd.DataFrame()\n",
    "        for s in signalList:\n",
    "            dataCon[s] = data[s]['processed'] \n",
    "            \n",
    "        # Ensure there are 30000 rows\n",
    "        if dataCon.shape[0] != int(Fs * fileLength):\n",
    "            print 'ill-sized dataframe'\n",
    "            continue\n",
    "        \n",
    "        # Group the data into intervals\n",
    "        dataCon['interval'] = pd.cut(dataCon.index,binEdge)\n",
    "        grouped = dataCon.groupby('interval')\n",
    "        \n",
    "        # Compute the mean\n",
    "        gMean = grouped.aggregate(mixedMean)\n",
    "        gMean.columns = [c + '_mean' for c in gMean.columns]\n",
    "        \n",
    "        # Compute the std\n",
    "        gStd = grouped.aggregate(np.std)\n",
    "        gStd.columns = [c + '_std' for c in gStd.columns]\n",
    "        \n",
    "        # Compute the min\n",
    "        gMin = grouped.aggregate(np.min)\n",
    "        gMin.columns = [c + '_min' for c in gMin.columns]\n",
    "        \n",
    "        # Compute the max\n",
    "        gMax = grouped.aggregate(np.max)\n",
    "        gMax.columns = [c + '_max' for c in gMax.columns]\n",
    "        \n",
    "        # Compute the del\n",
    "        gDEL = grouped.aggregate(mixedDEL)\n",
    "        gDEL.columns = [c + '_del' for c in gDEL.columns]\n",
    "        \n",
    "        # Merge the dataframes\n",
    "        merged = pd.concat([gMean,gStd,gMin,gMax,gDEL],axis=1)\n",
    "        \n",
    "        # Filter down by power and wind direction\n",
    "        merged = merged[merged.ApparentPower_mean > powLim]\n",
    "        merged = merged[(merged.WD1_87m_mean > yawLim[0]) | (merged.WD1_87m_mean < yawLim[1])]\n",
    "        \n",
    "        # Add a data column\n",
    "        merged['date'] = f[15:25]\n",
    "        \n",
    "        #Record this filename\n",
    "        with open(filenameFile, 'a') as ff:\n",
    "            ff.write(f + '\\n')\n",
    "        \n",
    "        \n",
    "        if (merged.shape[0] == 0):\n",
    "            print '..... no rows meet criteria, skipping'\n",
    "            if justOne:\n",
    "                break\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        \n",
    "        # Write to file\n",
    "        if not os.path.isfile(outputFile):\n",
    "            print 'creating file'\n",
    "            with open(outputFile,'w') as ff:\n",
    "                merged.to_csv(ff, header=True, index=False)\n",
    "        else:\n",
    "            print '...... WRITE TO FILE'\n",
    "            with open(outputFile, 'a') as ff:\n",
    "                merged.to_csv(ff, header=False,index=False)\n",
    "                \n",
    "\n",
    "        \n",
    "        if justOne:\n",
    "            break\n",
    "    \n",
    "    if justOne:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "justOne=False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
